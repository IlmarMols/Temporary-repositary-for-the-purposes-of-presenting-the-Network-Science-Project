{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bfe85a7",
   "metadata": {},
   "source": [
    "**Siin on minu esimene attempt birdwatchi andmetest aru saada**\n",
    "\n",
    "Lühidalt - birdwatchil of fail(allalaetult oli ta nimi note_request), mille eesmärk on hoida järge tweetidest, millele on palutud community noti lisamist. Plaanisin sealt võtta url-id, aga nad ei klapi olemasolevate mujal olevate tweetide infoga piisavalt, et ma saaksin tweetide veebiaadresse nii üles otsima hakata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55165cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\molsi\\AppData\\Local\\Temp\\ipykernel_8812\\816406038.py:6: DtypeWarning: Columns (10,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_status = pd.read_csv(\"data/noteStatusHistory-00000.tsv\", sep=\"\\t\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 1893175529995460774 – leiti link, aga note pole (või pole staatuses andmeid).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Laeme note_request.tsv ja noteStatusHistory\n",
    "df_request = pd.read_csv(\"data/note_request.tsv\", sep=\"\\t\")\n",
    "df_status = pd.read_csv(\"data/noteStatusHistory-00000.tsv\", sep=\"\\t\")\n",
    "\n",
    "# --- Puhasta status-tabel ---\n",
    "df_status = df_status[['noteId', 'currentStatus']]\n",
    "df_status['noteId'] = df_status['noteId'].astype(str)\n",
    "\n",
    "# --- Lisa sourceLinkis olev tweetId uue veeruna ---\n",
    "def extract_tweet_id_from_url(url):\n",
    "    if isinstance(url, str):\n",
    "        match = re.search(r\"status/(\\d+)\", url)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return None\n",
    "\n",
    "df_request['sourceTweetId'] = df_request['sourceLink'].apply(extract_tweet_id_from_url)\n",
    "\n",
    "# Loome lihtsa lookup-tabeli kõigi note tweetide jaoks (tuleb teiselt poolt – nt kui noteId==noteTweetId)\n",
    "note_tweet_lookup = df_status.copy()\n",
    "note_tweet_lookup['noteTweetId'] = note_tweet_lookup['noteId']  # oletame note tweetId = noteId (kui pole muud infot)\n",
    "note_tweet_lookup = note_tweet_lookup[['noteTweetId', 'currentStatus']]\n",
    "\n",
    "# --- Ühendame ---\n",
    "df_request['sourceTweetId'] = df_request['sourceTweetId'].astype(str)\n",
    "df_check = df_request.merge(note_tweet_lookup, left_on='sourceTweetId', right_on='noteTweetId', how='left')\n",
    "\n",
    "# Näitame ainult säutsud, mille kohta leidub note\n",
    "df_with_notes = df_check[~df_check['currentStatus'].isna()]\n",
    "\n",
    "# --- Kontroll ühe säutsu kohta ---\n",
    "def check_note_status_for_tweet(tweet_id):\n",
    "    row = df_check[df_check['tweetId'] == tweet_id]\n",
    "    if row.empty:\n",
    "        return f\"Tweet {tweet_id} – ei leitud üldse infot.\"\n",
    "    elif pd.isna(row.iloc[0]['currentStatus']):\n",
    "        return f\"Tweet {tweet_id} – leiti link, aga note pole (või pole staatuses andmeid).\"\n",
    "    else:\n",
    "        return f\"Tweet {tweet_id} – seotud note on staatusega {row.iloc[0]['currentStatus']}.\"\n",
    "\n",
    "# Kontrollime ühte säutsu\n",
    "print(check_note_status_for_tweet(1893175529995460774)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32329e1f",
   "metadata": {},
   "source": [
    "**Katse, kas tweetide kätte saamine twitteri api-st on võimalik**\n",
    "See muidi töötas - aga ma olen seda liiga tihti jooksutanud, seega hetkel on tulemus veidi misleading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7db583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viga säutsu päringus: 429\n",
      "\n",
      "Community Notes URL (manuaalne kontroll):\n",
      "https://twitter.com/i/communitynotes/1866605307595768005\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAAOP%2B2AEAAAAAsYeRbAqf0KTfRl52w2Kn7GR2RHs%3DAwMf7ynIdnsueFxb5BvFEJLROvzi1qowVlQ7jUq8TWQCE8rHR4'\n",
    "\n",
    "tweet_id = \"1866605307595768005\"\n",
    "\n",
    "# 1. Pärime säutsu andmed\n",
    "tweet_url = f\"https://api.twitter.com/2/tweets/{tweet_id}\"\n",
    "params = {\n",
    "    \"tweet.fields\": \"created_at,author_id,public_metrics,context_annotations\",\n",
    "    \"expansions\": \"author_id\"\n",
    "}\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {bearer_token}\"\n",
    "}\n",
    "\n",
    "tweet_response = requests.get(tweet_url, headers=headers, params=params)\n",
    "\n",
    "if tweet_response.status_code == 200:\n",
    "    tweet_data = tweet_response.json()\n",
    "    tweet_text = tweet_data.get(\"data\", {}).get(\"text\", \"Puudub tekst\")\n",
    "    author_id = tweet_data.get(\"data\", {}).get(\"author_id\", \"Tundmatu\")\n",
    "    \n",
    "    print(\"Säutsu tekst:\")\n",
    "    print(tweet_text)\n",
    "    print(\"Säutsu link:\")\n",
    "    print( tweet_data.get(\"data\", {}).get(\"url\", \"Puudub tekst\"))\n",
    "    #print(\"tweet_data:\",tweet_data)\n",
    "    print(f\"\\nAutor ID: {author_id}\")\n",
    "\n",
    "else:\n",
    "    print(\"Viga säutsu päringus:\", tweet_response.status_code)\n",
    "    exit()\n",
    "\n",
    "# 2. Proovime vaadata, kas Community Note on lisatud (Birdwatch API public note endpoint puudub)\n",
    "# Siin on ainult võimalik alternatiiv: kasutada otseteed Birdwatch web-URL-iks:\n",
    "print(f\"\\nCommunity Notes URL (manuaalne kontroll):\")\n",
    "print(f\"https://twitter.com/i/communitynotes/{tweet_id}\")\n",
    "\n",
    "# 3. Oota, et mitte ületada Twitter API rate limit'e\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1ef379",
   "metadata": {},
   "source": [
    "**ALL ON JÄÄNUSED MINU KATSETEST ÜRITADA Node2Vec KÄIMA SAADA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b857b974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing dependencies of omegaconf: .* suffix can only be used with `==` or `!=` operators\n",
      "    PyYAML (>=5.1.*)\n",
      "            ~~~~~~^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting umap-learn\n",
      "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from umap-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.3.1 in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from umap-learn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from umap-learn) (1.5.0)\n",
      "Collecting numba>=0.51.2 (from umap-learn)\n",
      "  Downloading numba-0.61.2-cp311-cp311-win_amd64.whl.metadata (2.9 kB)\n",
      "Collecting pynndescent>=0.5 (from umap-learn)\n",
      "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from umap-learn) (4.67.0)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51.2->umap-learn)\n",
      "  Downloading llvmlite-0.44.0-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pynndescent>=0.5->umap-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn>=0.22->umap-learn) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->umap-learn) (0.4.6)\n",
      "Downloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
      "Downloading numba-0.61.2-cp311-cp311-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 2.6/2.8 MB 18.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 9.7 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.44.0-cp311-cp311-win_amd64.whl (30.3 MB)\n",
      "   ---------------------------------------- 0.0/30.3 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 5.0/30.3 MB 23.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 10.5/30.3 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 16.3/30.3 MB 24.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 21.5/30.3 MB 24.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 26.5/30.3 MB 24.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  30.1/30.3 MB 24.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 30.3/30.3 MB 20.7 MB/s eta 0:00:00\n",
      "Downloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "Installing collected packages: llvmlite, numba, pynndescent, umap-learn\n",
      "\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------------------------------------- 0/4 [llvmlite]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   ---------- ----------------------------- 1/4 [numba]\n",
      "   -------------------- ------------------- 2/4 [pynndescent]\n",
      "   -------------------- ------------------- 2/4 [pynndescent]\n",
      "   -------------------- ------------------- 2/4 [pynndescent]\n",
      "   -------------------- ------------------- 2/4 [pynndescent]\n",
      "   -------------------- ------------------- 2/4 [pynndescent]\n",
      "   ------------------------------ --------- 3/4 [umap-learn]\n",
      "   ------------------------------ --------- 3/4 [umap-learn]\n",
      "   ------------------------------ --------- 3/4 [umap-learn]\n",
      "   ------------------------------ --------- 3/4 [umap-learn]\n",
      "   ------------------------------ --------- 3/4 [umap-learn]\n",
      "   ------------------------------ --------- 3/4 [umap-learn]\n",
      "   ---------------------------------------- 4/4 [umap-learn]\n",
      "\n",
      "Successfully installed llvmlite-0.44.0 numba-0.61.2 pynndescent-0.5.13 umap-learn-0.5.7\n"
     ]
    }
   ],
   "source": [
    "#!pip install node2vec\n",
    "#!pip install --upgrade numpy gensim Cython\n",
    "#!pip install pandas numpy networkx matplotlib seaborn scikit-learn node2vec\n",
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e30e758a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing dependencies of omegaconf: .* suffix can only be used with `==` or `!=` operators\n",
      "    PyYAML (>=5.1.*)\n",
      "            ~~~~~~^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch_geometric) (3.11.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch_geometric) (2024.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch_geometric) (1.24.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch_geometric) (6.0.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch_geometric) (3.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch_geometric) (4.67.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->torch_geometric) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->torch_geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->torch_geometric) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->torch_geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->torch_geometric) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->torch_geometric) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->torch_geometric) (1.17.2)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->torch_geometric) (3.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch_geometric) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torch_geometric) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torch_geometric) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torch_geometric) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\molsi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->torch_geometric) (0.4.6)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.3/1.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.3/1.1 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.5/1.1 MB 764.3 kB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.5/1.1 MB 764.3 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 0.8/1.1 MB 714.3 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.0/1.1 MB 719.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 707.9 kB/s eta 0:00:00\n",
      "Installing collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.6.1\n"
     ]
    }
   ],
   "source": [
    "#!pip uninstall -y numpy scipy gensim Cython\n",
    "#!pip install numpy==1.24.4 scipy==1.11.4 gensim==4.3.1 Cython\n",
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fa86b4",
   "metadata": {},
   "source": [
    "**Siin on GraphSAGE-iga tehtud katse luua võrgustikku**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb7abf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\molsi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0379,  0.1110],\n",
      "        [ 0.2874, -0.2452],\n",
      "        [ 0.3121, -0.0219],\n",
      "        [-0.4075, -0.0450]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "# Example: small graph with 4 nodes and edges\n",
    "edge_index = torch.tensor([\n",
    "    [0, 1, 1, 2, 3],\n",
    "    [1, 0, 2, 1, 0]\n",
    "], dtype=torch.long)\n",
    "\n",
    "# Node features (4 nodes, 3 features each)\n",
    "x = torch.randn((4, 3))\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GraphSAGE(in_channels=3, hidden_channels=5, out_channels=2)\n",
    "\n",
    "out = model(data.x, data.edge_index)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec0c64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[1540527, 1], edge_index=[2, 13618878])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\molsi\\AppData\\Local\\Temp\\ipykernel_14564\\4115226570.py:26: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  edge_index = torch.tensor([src, dst], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "\n",
    "# Ainult üks fail, et testida\n",
    "file_path = \"./data/ratings-00000.tsv\"\n",
    "ratings = pd.read_csv(file_path, sep='\\t', low_memory=False)\n",
    "\n",
    "# Vali ainult vajalikud veerud ja dropi tühjad\n",
    "ratings = ratings[['noteId', 'raterParticipantId', 'helpful']]\n",
    "ratings.dropna(subset=['noteId', 'raterParticipantId'], inplace=True)\n",
    "\n",
    "unique_nodes = pd.Index(\n",
    "    ratings['noteId'].astype(str).tolist() +\n",
    "    ratings['raterParticipantId'].astype(str).tolist()\n",
    ").unique()\n",
    "\n",
    "node2idx = {node: idx for idx, node in enumerate(unique_nodes)}\n",
    "\n",
    "# Loome edge_index tensorid\n",
    "src = ratings['raterParticipantId'].astype(str).map(node2idx).values\n",
    "dst = ratings['noteId'].astype(str).map(node2idx).values\n",
    "\n",
    "edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "\n",
    "# Dummy node feature (kõik 1)\n",
    "x = torch.ones((len(unique_nodes), 1), dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee531d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 8.9966\n",
      "Epoch 2, Loss: 6.2593\n",
      "Epoch 3, Loss: 3.8905\n",
      "Epoch 4, Loss: 3.6471\n",
      "Epoch 5, Loss: 3.5774\n",
      "Epoch 6, Loss: 2.5202\n",
      "Epoch 7, Loss: 1.3770\n",
      "Epoch 8, Loss: 0.8565\n",
      "Epoch 9, Loss: 0.9608\n",
      "Epoch 10, Loss: 1.2818\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.loader import NeighborSampler\n",
    "\n",
    "# Väike GraphSAGE mudel\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GraphSAGE(in_channels=1, hidden_channels=64, out_channels=32).to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.02)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10): \n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = (out.norm(dim=1) ** 2).mean() \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09bf1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "embeddings = model(data.x, data.edge_index).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a79f41",
   "metadata": {},
   "source": [
    "The rest of the code above is now gone (didn't save before creating the network with large data - so it freezed and the code is gone)\n",
    "\n",
    "**Below is how i made the current reults by using the TruncatedSVD, KMeans and umap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcdddc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\molsi\\AppData\\Local\\Temp\\ipykernel_14564\\281983218.py:10: DtypeWarning: Columns (10,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  note_status = pd.read_csv(\"data/noteStatusHistory-00000.tsv\", sep='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENTLY_RATED_HELPFUL        232367\n",
      "CURRENTLY_RATED_NOT_HELPFUL    132457\n",
      "Name: mostRecentNonNMRStatus, dtype: int64\n",
      "Approved notes: 232367\n",
      "Reading data/ratings-00000.tsv ...\n",
      "Reading data/ratings-00008.tsv ...\n",
      "Ratings shape after filtering: (6475758, 2)\n",
      "Number of unique notes: 231274\n",
      "Number of unique raters: 202897\n",
      "Adjacency matrix shape: (231274, 202897)\n",
      "adj_matrix:   (0, 0)\t1.0\n",
      "  (0, 31)\t1.0\n",
      "  (0, 189)\t1.0\n",
      "  (0, 776)\t1.0\n",
      "  (0, 1177)\t1.0\n",
      "  (0, 1196)\t1.0\n",
      "  (0, 1653)\t1.0\n",
      "  (0, 1756)\t1.0\n",
      "  (0, 1806)\t1.0\n",
      "  (0, 2068)\t1.0\n",
      "  (0, 2266)\t1.0\n",
      "  (0, 2282)\t1.0\n",
      "  (0, 2609)\t1.0\n",
      "  (0, 2626)\t1.0\n",
      "  (0, 2679)\t1.0\n",
      "  (0, 2774)\t1.0\n",
      "  (0, 3055)\t1.0\n",
      "  (0, 3180)\t1.0\n",
      "  (0, 3534)\t1.0\n",
      "  (0, 3812)\t1.0\n",
      "  (0, 3847)\t1.0\n",
      "  (0, 3862)\t1.0\n",
      "  (0, 3952)\t1.0\n",
      "  (0, 3972)\t1.0\n",
      "  (0, 4111)\t1.0\n",
      "  :\t:\n",
      "  (231249, 200970)\t1.0\n",
      "  (231250, 200970)\t1.0\n",
      "  (231251, 201234)\t1.0\n",
      "  (231252, 201580)\t1.0\n",
      "  (231253, 201709)\t1.0\n",
      "  (231254, 201725)\t1.0\n",
      "  (231255, 201734)\t1.0\n",
      "  (231256, 201781)\t1.0\n",
      "  (231257, 201831)\t1.0\n",
      "  (231258, 201834)\t1.0\n",
      "  (231259, 201858)\t1.0\n",
      "  (231260, 202017)\t1.0\n",
      "  (231261, 202039)\t1.0\n",
      "  (231262, 202049)\t1.0\n",
      "  (231263, 202168)\t1.0\n",
      "  (231264, 202193)\t1.0\n",
      "  (231265, 202195)\t1.0\n",
      "  (231266, 202395)\t1.0\n",
      "  (231267, 202440)\t1.0\n",
      "  (231268, 202476)\t1.0\n",
      "  (231269, 202487)\t1.0\n",
      "  (231270, 202541)\t1.0\n",
      "  (231271, 202621)\t1.0\n",
      "  (231272, 202724)\t1.0\n",
      "  (231273, 202873)\t1.0\n",
      "svd_notes: TruncatedSVD(n_components=32, random_state=42)\n",
      "Notes embeddings shape: (231274, 32)\n",
      "Raters embeddings shape: (202897, 32)\n",
      "Saved graph_embeddings_notes.csv\n",
      "Saved graph_embeddings_raters.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "note_status = pd.read_csv(\"data/noteStatusHistory-00000.tsv\", sep='\\t')\n",
    "\n",
    "print(note_status['mostRecentNonNMRStatus'].value_counts())\n",
    "\n",
    "# Võta ainult approved notes\n",
    "approved_notes = note_status[note_status['mostRecentNonNMRStatus'] == \"CURRENTLY_RATED_HELPFUL\"]['noteId'].unique()\n",
    "print(f\"Approved notes: {len(approved_notes)}\")\n",
    "\n",
    "\n",
    "ratings_files = [\n",
    "    \"data/ratings-00000.tsv\",\n",
    "    \"data/ratings-00008.tsv\"\n",
    "]\n",
    "\n",
    "# Vaid vajalikud veerud\n",
    "usecols = ['noteId', 'raterParticipantId']\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "for file in ratings_files:\n",
    "    print(f\"Reading {file} ...\")\n",
    "    chunksize = 10 ** 6  # loeme 1M rida korraga\n",
    "    for chunk in pd.read_csv(file, sep='\\t', usecols=usecols, chunksize=chunksize):\n",
    "        # Filtreeri approved notes\n",
    "        chunk = chunk[chunk['noteId'].isin(approved_notes)]\n",
    "        all_rows.append(chunk)\n",
    "\n",
    "ratings = pd.concat(all_rows, ignore_index=True)\n",
    "print(f\"Ratings shape after filtering: {ratings.shape}\")\n",
    "\n",
    "\n",
    "noteId_to_idx = {nid: i for i, nid in enumerate(ratings['noteId'].unique())}\n",
    "raterId_to_idx = {rid: i for i, rid in enumerate(ratings['raterParticipantId'].unique())}\n",
    "\n",
    "num_notes = len(noteId_to_idx)\n",
    "num_raters = len(raterId_to_idx)\n",
    "\n",
    "print(f\"Number of unique notes: {num_notes}\")\n",
    "print(f\"Number of unique raters: {num_raters}\")\n",
    "\n",
    "# Build CSR matrix\n",
    "rows = ratings['noteId'].map(noteId_to_idx).values\n",
    "cols = ratings['raterParticipantId'].map(raterId_to_idx).values\n",
    "data = np.ones(len(ratings))\n",
    "\n",
    "adj_matrix = csr_matrix((data, (rows, cols)), shape=(num_notes, num_raters))\n",
    "print(f\"Adjacency matrix shape: {adj_matrix.shape}\")\n",
    "\n",
    "# 4️ Embeddings\n",
    "\n",
    "svd_dim = 32\n",
    "\n",
    "svd_notes = TruncatedSVD(n_components=svd_dim, random_state=42)\n",
    "print(\"adj_matrix:\",adj_matrix)\n",
    "print(\"svd_notes:\",svd_notes)\n",
    "notes_embeddings = svd_notes.fit_transform(adj_matrix)\n",
    "\n",
    "svd_raters = TruncatedSVD(n_components=svd_dim, random_state=42)\n",
    "raters_embeddings = svd_raters.fit_transform(adj_matrix.T)\n",
    "\n",
    "print(f\"Notes embeddings shape: {notes_embeddings.shape}\")\n",
    "print(f\"Raters embeddings shape: {raters_embeddings.shape}\")\n",
    "\n",
    "# 5️ Clustering\n",
    "\n",
    "num_note_clusters = 20\n",
    "kmeans_notes = KMeans(n_clusters=num_note_clusters, random_state=42)\n",
    "note_labels = kmeans_notes.fit_predict(notes_embeddings)\n",
    "\n",
    "num_rater_clusters = 10\n",
    "kmeans_raters = KMeans(n_clusters=num_rater_clusters, random_state=42)\n",
    "rater_labels = kmeans_raters.fit_predict(raters_embeddings)\n",
    "\n",
    "# 6️ Save results\n",
    "\n",
    "note_idx_to_id = {v: k for k, v in noteId_to_idx.items()}\n",
    "df_notes = pd.DataFrame(notes_embeddings, columns=[f\"emb_{i}\" for i in range(svd_dim)])\n",
    "df_notes['noteId'] = df_notes.index.map(note_idx_to_id)\n",
    "df_notes['cluster'] = note_labels\n",
    "\n",
    "df_notes.to_csv(\"graph_embeddings_notes.csv\", index=False)\n",
    "print(\"Saved graph_embeddings_notes.csv\")\n",
    "\n",
    "# Raters dataframe\n",
    "rater_idx_to_id = {v: k for k, v in raterId_to_idx.items()}\n",
    "df_raters = pd.DataFrame(raters_embeddings, columns=[f\"emb_{i}\" for i in range(svd_dim)])\n",
    "df_raters['raterParticipantId'] = df_raters.index.map(rater_idx_to_id)\n",
    "df_raters['cluster'] = rater_labels\n",
    "\n",
    "df_raters.to_csv(\"graph_embeddings_raters.csv\", index=False)\n",
    "print(\"Saved graph_embeddings_raters.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02022836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notes embeddings loaded: (231274, 34)\n",
      "Raters embeddings loaded: (202897, 34)\n",
      "Fitting UMAP on notes ...\n",
      "UMAP(n_jobs=1, n_neighbors=30, random_state=42, verbose=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\molsi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun  6 17:42:18 2025 Construct fuzzy simplicial set\n",
      "Fri Jun  6 17:42:19 2025 Finding Nearest Neighbors\n",
      "Fri Jun  6 17:42:19 2025 Building RP forest with 29 trees\n",
      "Fri Jun  6 17:42:30 2025 NN descent for 18 iterations\n",
      "\t 1  /  18\n",
      "\t 2  /  18\n",
      "\t 3  /  18\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Fri Jun  6 17:43:19 2025 Finished Nearest Neighbor Search\n",
      "Fri Jun  6 17:43:23 2025 Construct embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:   1%|            2/200 [00:04]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  0  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  10%| █          21/200 [00:53]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  20  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  20%| ██         41/200 [01:45]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  40  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  31%| ███        62/200 [02:31]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  60  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  41%| ████       82/200 [03:04]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  80  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  51%| █████      102/200 [03:27]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  100  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  60%| ██████     121/200 [03:49]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  120  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  71%| ███████    142/200 [04:30]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  140  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  80%| ████████   161/200 [05:20]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  160  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  90%| █████████  181/200 [06:15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  180  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed: 100%| ██████████ 200/200 [07:03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun  6 17:53:33 2025 Finished embedding\n",
      "Saved graph_embeddings_notes_umap.csv\n",
      "Fitting UMAP on raters ...\n",
      "UMAP(n_jobs=1, n_neighbors=30, random_state=42, verbose=True)\n",
      "Fri Jun  6 17:54:04 2025 Construct fuzzy simplicial set\n",
      "Fri Jun  6 17:54:04 2025 Finding Nearest Neighbors\n",
      "Fri Jun  6 17:54:05 2025 Building RP forest with 28 trees\n",
      "Fri Jun  6 17:54:18 2025 NN descent for 18 iterations\n",
      "\t 1  /  18\n",
      "\t 2  /  18\n",
      "\t 3  /  18\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "Fri Jun  6 17:55:17 2025 Finished Nearest Neighbor Search\n",
      "Fri Jun  6 17:55:23 2025 Construct embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:   1%|            2/200 [00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  0  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  11%| █          22/200 [00:50]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  20  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  20%| ██         41/200 [01:24]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  40  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  30%| ███        61/200 [01:42]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  60  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  40%| ████       81/200 [01:59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  80  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  51%| █████      102/200 [02:17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  100  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  60%| ██████     121/200 [03:02]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  120  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  70%| ███████    141/200 [03:20]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  140  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  81%| ████████   162/200 [03:35]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  160  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed:  91%| █████████  182/200 [03:50]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  180  /  200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed: 100%| ██████████ 200/200 [04:04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun  6 18:01:07 2025 Finished embedding\n",
      "Saved graph_embeddings_raters_umap.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import umap\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1️ Loeme notes embeddings\n",
    "df_notes = pd.read_csv(\"graph_embeddings_notes.csv\")\n",
    "print(f\"Notes embeddings loaded: {df_notes.shape}\")\n",
    "\n",
    "# 2️ Loeme raters embeddings\n",
    "df_raters = pd.read_csv(\"graph_embeddings_raters.csv\")\n",
    "print(f\"Raters embeddings loaded: {df_raters.shape}\")\n",
    "\n",
    "# 3️ UMAP config\n",
    "umap_model = umap.UMAP(n_neighbors=30, min_dist=0.1, n_components=2, random_state=42, verbose=True)\n",
    "\n",
    "# 4️ Notes UMAP\n",
    "print(\"Fitting UMAP on notes ...\")\n",
    "X_notes = df_notes.filter(like=\"emb_\").values\n",
    "notes_umap = umap_model.fit_transform(X_notes)\n",
    "\n",
    "df_notes['umap_X'] = notes_umap[:, 0]\n",
    "df_notes['umap_Y'] = notes_umap[:, 1]\n",
    "\n",
    "# Save\n",
    "df_notes.to_csv(\"graph_embeddings_notes_umap.csv\", index=False)\n",
    "print(\"Saved graph_embeddings_notes_umap.csv\")\n",
    "\n",
    "# 5️ Raters UMAP\n",
    "print(\"Fitting UMAP on raters ...\")\n",
    "X_raters = df_raters.filter(like=\"emb_\").values\n",
    "raters_umap = umap_model.fit_transform(X_raters)\n",
    "\n",
    "df_raters['umap_X'] = raters_umap[:, 0]\n",
    "df_raters['umap_Y'] = raters_umap[:, 1]\n",
    "\n",
    "# Save\n",
    "df_raters.to_csv(\"graph_embeddings_raters_umap.csv\", index=False)\n",
    "print(\"Saved graph_embeddings_raters_umap.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f158db6",
   "metadata": {},
   "source": [
    "**Siin puhastama segadustekitava andmestiku ja loome networkid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11110857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "df_notes = pd.read_csv(\"graph_embeddings_notes.csv\")\n",
    "df_raters = pd.read_csv(\"graph_embeddings_raters.csv\")\n",
    "ratings = pd.read_csv(\"data/ratings-00000.tsv\", sep='\\t', usecols=['noteId', 'raterParticipantId'])\n",
    "\n",
    "# Lisa klastrid\n",
    "ratings = ratings.merge(df_notes[['noteId', 'cluster']], on='noteId', how='inner')\n",
    "ratings = ratings.merge(df_raters[['raterParticipantId', 'cluster']], on='raterParticipantId', how='inner', suffixes=('_note', '_rater'))\n",
    "\n",
    "# ⛓️ Edge list: ühenduste tugevused rater-note klastri vahel\n",
    "edge_df = ratings.groupby(['cluster_rater', 'cluster_note']).size().reset_index(name='weight')\n",
    "edge_df['source'] = 'R_' + edge_df['cluster_rater'].astype(str)\n",
    "edge_df['target'] = 'N_' + edge_df['cluster_note'].astype(str)\n",
    "\n",
    "# Salvestame edge listi\n",
    "edge_df[['source', 'target', 'weight']].to_csv(\"cluster_edges.csv\", index=False)\n",
    "\n",
    "# Node list: kõik sõlmed koos tüübiga ja suurusega\n",
    "rater_cluster_sizes = df_raters['cluster'].value_counts().reset_index()\n",
    "rater_cluster_sizes.columns = ['id', 'size']\n",
    "rater_cluster_sizes['id'] = 'R_' + rater_cluster_sizes['id'].astype(str)\n",
    "rater_cluster_sizes['type'] = 'rater'\n",
    "\n",
    "note_cluster_sizes = df_notes['cluster'].value_counts().reset_index()\n",
    "note_cluster_sizes.columns = ['id', 'size']\n",
    "note_cluster_sizes['id'] = 'N_' + note_cluster_sizes['id'].astype(str)\n",
    "note_cluster_sizes['type'] = 'note'\n",
    "\n",
    "node_df = pd.concat([rater_cluster_sizes, note_cluster_sizes])\n",
    "node_df.to_csv(\"cluster_nodes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "172cf24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cluster               noteId\n",
      "0         0  1871404259142459857\n",
      "1         1  1865590698902503921\n",
      "2         2  1679319580831883264\n",
      "3         3  1779207915749916889\n",
      "4         4  1844374392169812149\n",
      "5         5  1733821630449668329\n",
      "6         6  1762849587457622499\n",
      "7         7  1702285661330722930\n",
      "8         8  1677545815458594819\n",
      "9         9  1771990281727963467\n",
      "10       10  1782863374235099220\n",
      "11       11  1800717246706196808\n",
      "12       12  1727529309810655291\n",
      "13       13  1673568883695923201\n",
      "14       14  1714589572200304695\n",
      "15       15  1776426205035819122\n",
      "16       16  1818973938346815666\n",
      "17       17  1727034787293274506\n",
      "18       18  1818243351017341150\n",
      "19       19  1710821689636934115\n"
     ]
    }
   ],
   "source": [
    "one_note_per_cluster = df_notes.groupby('cluster')['noteId'].first().reset_index()\n",
    "print(one_note_per_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "063f7837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viga päringus tweetId 1871404259142459857: 429\n",
      "Viga päringus tweetId 1865590698902503921: 429\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m     59\u001b[0m         \u001b[38;5;66;03m# Võid siin töödelda või salvestada JSONi\u001b[39;00m\n\u001b[0;32m     60\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m---> 61\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# et mitte ületada rate limite (Twitter soovitab 1 päring sekundis)\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Näide: prindi esimese tweeti tekst\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAAOP%2B2AEAAAAAUa30N6XR7pwI1MySlBxCp5J2LEw%3DuQZOFyoSaBeDbKKDsj094lrFb9GEa8UMX7E1TjKphDA2XG1q94'\n",
    "\n",
    "tweet_ids = [\n",
    "    \"1871404259142459857\",\n",
    "    \"1865590698902503921\",\n",
    "    \"1679319580831883264\",\n",
    "    \"1779207915749916889\",\n",
    "    \"1844374392169812149\",\n",
    "    \"1733821630449668329\",\n",
    "    \"1762849587457622499\",\n",
    "    \"1702285661330722930\",\n",
    "    \"1677545815458594819\",\n",
    "    \"1771990281727963467\",\n",
    "    \"1782863374235099220\",\n",
    "    \"1800717246706196808\",\n",
    "    \"1727529309810655291\",\n",
    "    \"1673568883695923201\",\n",
    "    \"1714589572200304695\",\n",
    "    \"1776426205035819122\",\n",
    "    \"1818973938346815666\",\n",
    "    \"1727034787293274506\",\n",
    "    \"1818243351017341150\",\n",
    "    \"1710821689636934115\"\n",
    "]\n",
    "\n",
    "def get_tweet_data(tweet_id, bearer_token):\n",
    "    tweet_url = f\"https://api.twitter.com/2/tweets/{tweet_id}\"\n",
    "    params = {\n",
    "        \"tweet.fields\": \"created_at,author_id,public_metrics,context_annotations\",\n",
    "        \"expansions\": \"author_id\"\n",
    "    }\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {bearer_token}\"\n",
    "    }\n",
    "\n",
    "    tweet_response = requests.get(tweet_url, headers=headers, params=params)\n",
    "\n",
    "    if tweet_response.status_code == 200:\n",
    "        tweet_data = tweet_response.json()\n",
    "        tweet_text = tweet_data.get(\"data\", {}).get(\"text\", \"Puudub tekst\")\n",
    "        author_id = tweet_data.get(\"data\", {}).get(\"author_id\", \"Tundmatu\")\n",
    "\n",
    "        print(\"Säutsu tekst:\")\n",
    "        print(tweet_text)\n",
    "        print(\"Säutsu link:\")\n",
    "        print( tweet_data.get(\"data\", {}).get(\"url\", \"Puudub tekst\"))\n",
    "        #print(\"tweet_data:\",tweet_data)\n",
    "        print(f\"\\nAutor ID: {author_id}\")\n",
    "        return tweet_text\n",
    "    else:\n",
    "        print(f\"Viga päringus tweetId {tweet_id}: {tweet_response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "results = []\n",
    "\n",
    "for tid in tweet_ids:\n",
    "    data = get_tweet_data(tid, bearer_token)\n",
    "    if data:\n",
    "        # Võid siin töödelda või salvestada JSONi\n",
    "        results.append(data)\n",
    "    time.sleep(5)  # et mitte ületada rate limite (Twitter soovitab 1 päring sekundis)\n",
    "\n",
    "# Näide: prindi esimese tweeti tekst\n",
    "if results:\n",
    "    print(results[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
